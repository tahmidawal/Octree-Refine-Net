Run directory: training_logs/20260206_020641
Model parameters | Total: 301,826 | Trainable: 301,762
Device: cuda
Task: Reconstruct Coarse + Autoencode Patch A + Generate Patch B
Starting training...
Epoch 0 | Total: 0.56921 | Coarse: 0.11292 | Recon A: 0.23144 | Gen B: 0.22484
Epoch 100 | Total: 0.00612 | Coarse: 0.00049 | Recon A: 0.00177 | Gen B: 0.00386
Epoch 200 | Total: 0.00225 | Coarse: 0.00032 | Recon A: 0.00085 | Gen B: 0.00108
Epoch 300 | Total: 0.00110 | Coarse: 0.00016 | Recon A: 0.00047 | Gen B: 0.00047
Epoch 400 | Total: 0.00135 | Coarse: 0.00015 | Recon A: 0.00053 | Gen B: 0.00067
Epoch 500 | Total: 0.00097 | Coarse: 0.00011 | Recon A: 0.00044 | Gen B: 0.00042
Epoch 600 | Total: 0.00070 | Coarse: 0.00009 | Recon A: 0.00026 | Gen B: 0.00035
Epoch 700 | Total: 0.00063 | Coarse: 0.00007 | Recon A: 0.00025 | Gen B: 0.00030
Epoch 800 | Total: 0.00058 | Coarse: 0.00007 | Recon A: 0.00022 | Gen B: 0.00030
Epoch 900 | Total: 0.00068 | Coarse: 0.00005 | Recon A: 0.00033 | Gen B: 0.00030
Epoch 1000 | Total: 0.00072 | Coarse: 0.00006 | Recon A: 0.00025 | Gen B: 0.00040
Saved loss curve to training_logs/20260206_020641/plots/loss_curve.png

--- FINAL EVALUATION (Comparison vs Bicubic) ---
Sample 0:
  Patch A (Recon) MSE: 0.000504
  Patch B (Gen)   MSE: 0.000240 vs Bicubic: 0.008232
  >>> Neural is 34.3x better than Bicubic
Sample 1:
  Patch A (Recon) MSE: 0.000355
  Patch B (Gen)   MSE: 0.000447 vs Bicubic: 0.009101
  >>> Neural is 20.3x better than Bicubic
Sample 2:
  Patch A (Recon) MSE: 0.000427
  Patch B (Gen)   MSE: 0.000340 vs Bicubic: 0.005731
  >>> Neural is 16.9x better than Bicubic
Sample 3:
  Patch A (Recon) MSE: 0.000466
  Patch B (Gen)   MSE: 0.000272 vs Bicubic: 0.006297
  >>> Neural is 23.2x better than Bicubic

================================================================================
FAIR COMPARISON: PROJECTED ERROR TEST (All errors measured at Fine Scale 40x40)
================================================================================
Comparing against TRUE HIGH-RES GROUND TRUTH to verify refinement adds real accuracy
--------------------------------------------------------------------------------
Sample   Coarse->Fine MSE   Neural Fine MSE    Improvement    
--------------------------------------------------------------------------------
0        0.008115           0.000240           33.8           x
1        0.008947           0.000447           20.0           x
2        0.006030           0.000340           17.8           x
3        0.005837           0.000272           21.5           x
--------------------------------------------------------------------------------
Interpretation:
  - Coarse->Fine MSE: Error when using upsampled coarse reconstruction
  - Neural Fine MSE:  Error of the neural refinement
  - Improvement > 1:  Neural refinement adds REAL accuracy over coarse
================================================================================

================================================================================
REVERSE PROJECTION: Coarse Reconstruction vs Downsampled FULL 1024x1024 Fine GT
================================================================================
Generate TRUE 1024x1024 fine GT, downsample to 256x256, compare with coarse reconstruction
--------------------------------------------------------------------------------
Sample   Full Coarse MSE    Full Coarse RelL2   
--------------------------------------------------------------------------------
0        0.010946           0.317230            
1        0.005537           0.219163            
2        0.004049           0.185175            
3        0.005735           0.221462            
--------------------------------------------------------------------------------

Patch-level comparison (Fine GT downsampled to coarse 10x10):
Sample   Patch      Coarse Recon MSE   Coarse Recon RelL2  
--------------------------------------------------------------------------------
0        A          0.010486           0.300892            
0        B          0.008541           0.269213            
1        A          0.011540           0.266673            
1        B          0.005441           0.231247            
2        A          0.006959           0.312065            
2        B          0.004269           0.191976            
3        A          0.010090           0.248719            
3        B          0.004382           0.191643            
--------------------------------------------------------------------------------
Interpretation:
  - Full Coarse MSE: Error of 256x256 coarse reconstruction vs downsampled 1024x1024 fine GT
  - Patch Coarse MSE: Error at specific patch locations
  - This tests if coarse reconstruction matches what the TRUE fine signal looks like at coarse scale
================================================================================

--- GENERATING FULL QUADTREE ERROR PLOTS ---

--- RELATIVE L2 ERROR SUMMARY ---
Sample   Coarse RelL2    Patch A RelL2   Patch B RelL2   Patch B Bicubic RelL2
---------------------------------------------------------------------------
0        0.023756        0.051964        0.049610        0.290525            
1        0.031917        0.049246        0.057302        0.258464            
2        0.024654        0.055293        0.061573        0.252924            
3        0.033889        0.050924        0.047957        0.230816            
---------------------------------------------------------------------------
Saved full quadtree error plots for 4 samples to training_logs/20260206_020641/plots/
